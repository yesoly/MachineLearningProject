{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment-06.ipynb",
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "1jhbp5ntq1aCzd5KZJe73p2NSPTJIIg8l",
      "authorship_tag": "ABX9TyNKf3QEC1DKQOshmiKUj0VJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yesoly/MachineLearningProject/blob/master/Assignment_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_h4UlsYDmXP"
      },
      "source": [
        "# Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-2LtdF_F3lG"
      },
      "source": [
        "## 0. Import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pp4Mh8CVF1FJ"
      },
      "source": [
        "# Import libraries\n",
        "\n",
        "# math library\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# visualization library\n",
        "%matplotlib inline\n",
        "from IPython.display import set_matplotlib_formats\n",
        "set_matplotlib_formats('png2x','pdf')\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KYkHtwlFOyl"
      },
      "source": [
        "## 1. Load and plot the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxTxdcRvDaJ6"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# data path\n",
        "test_path = '/content/drive/My Drive/ML_Assignment/data/testing.txt'\n",
        "train_path = '/content/drive/My Drive/ML_Assignment/data/training.txt'\n",
        "\n",
        "# import data with numpy\n",
        "data_train  = np.loadtxt(train_path, delimiter=',')\n",
        "data_test   = np.loadtxt(test_path, delimiter=',')\n",
        "\n",
        "# number of training data\n",
        "number_data_train   = data_train.shape[0] \n",
        "number_data_test    = data_test.shape[0]\n",
        "\n",
        "# training data\n",
        "x1_train            = data_train[:,0] # feature 1\n",
        "x2_train            = data_train[:,1] # feature 2\n",
        "idx_class0_train    = (data_train[:,2]==0) # index of class0\n",
        "idx_class1_train    = (data_train[:,2]==1) # index of class1\n",
        "\n",
        "# testing data\n",
        "x1_test             = data_test[:,0] # feature 1\n",
        "x2_test             = data_test[:,1] # feature 2\n",
        "idx_class0_test     = (data_test[:,2]==0) # index of class0\n",
        "idx_class1_test     = (data_test[:,2]==1) # index of clas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qeKkYoTGDZp"
      },
      "source": [
        "fig_1 = plt.figure()\n",
        "plt.scatter(x1_train[idx_class0_train], x2_train[idx_class0_train], s=50, c='r', marker='.', label='label = 0') \n",
        "plt.scatter(x1_train[idx_class1_train], x2_train[idx_class1_train], s=50, c='b', marker='.', label='label = 1')\n",
        "plt.title('Training data')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "fig_1.savefig('Training data.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyFXEAYoHaz0"
      },
      "source": [
        "fig_2 = plt.figure()\n",
        "plt.scatter(x1_test[idx_class0_test], x2_test[idx_class0_test], s=50, c='r', marker='.', label='label = 0')\n",
        "plt.scatter(x1_test[idx_class1_test], x2_test[idx_class1_test], s=50, c='b', marker='.', label='label = 1')\n",
        "plt.title('Testing data')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "fig_2.savefig('Testing data.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yfwCoHmFVR9"
      },
      "source": [
        "##2. Define a logistic regression loss function and its gradient\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMDgydEo0i4b"
      },
      "source": [
        "# make X\n",
        "def function(x, y):\n",
        "  func_list = []\n",
        "  for i in range (0, 10, 1):\n",
        "    for j in range (0, 10, 1):\n",
        "      func_list.append((x**i)*(y**j))\n",
        "  func_list = torch.stack(func_list).squeeze(-1)\n",
        "  return func_list.T\n",
        "\n",
        "# g(x, y, w)\n",
        "def g_func(X, w):\n",
        "  pred = sigmoid(torch.matmul(X, w))\n",
        "  return pred\n",
        "\n",
        "# sigmoid function\n",
        "def sigmoid(z):\n",
        "    sigmoid_f = 1.0 / (1.0 + torch.exp(-z))\n",
        "    return sigmoid_f \n",
        "\n",
        "# loss function definition\n",
        "def loss_logreg(y_pred,y,w,lamb): \n",
        "    n = len(y)\n",
        "    cross_entropy = torch.sum(-y * torch.log(y_pred) - (1 - y) *  torch.log(1 - y_pred)) / n\n",
        "    r = torch.sum(w**2) * lamb * 0.5\n",
        "    loss = cross_entropy + r\n",
        "    return loss\n",
        "\n",
        "\n",
        "# gradient function definition\n",
        "def grad_loss(y_pred,y,X):\n",
        "    n = len(y)\n",
        "    grad = torch.sum((y_pred - y)* X[:,i].unsqueeze(1))/n\n",
        "    return grad\n",
        "\n",
        "\n",
        "# gradient descent function definition\n",
        "def grad_desc(X_train, X_test, y_train, y_test, tau, max_iter, lamb):\n",
        "    L_iters_train = np.zeros([max_iter]) # record the loss values\n",
        "    L_iters_test = np.zeros([max_iter])\n",
        "    w = np.array([[0.01] for j in range(100)]) # initialization\n",
        "    w = torch.tensor(w)\n",
        "    print('=================== Running Start ===================')\n",
        "    for i in range(max_iter): # loop over the iterations\n",
        "        train_pred = g_func(X_train, w) # linear predicition function\n",
        "        test_pred = g_func(X_test, w)  \n",
        "        for n in range(0, 100, 1) :\n",
        "          w[n] = (1 - tau*lamb) * w[n] - tau*torch.sum((train_pred - y_train)* X_train[:,n].unsqueeze(1))/len(y_train) # update rule of gradient descent         w[n] -= tau * torch.sum((train_pred - y_train)*X_train[:,n].unsqueeze(1))/len(y_train) + (lamb * w[n])\n",
        "        J_train = loss_logreg(train_pred,y_train,w,lamb)\n",
        "        J_test = loss_logreg(test_pred,y_test,w,lamb)\n",
        "        L_iters_train[i] = J_train # save the current loss value\n",
        "        L_iters_test[i] = J_test\n",
        "        if i % 10000 == 0:\n",
        "          print('Epoch: {:6d}, train_cost: {:10f}, test_cost: {:10f}'.format(i,J_train,J_test))\n",
        "        \n",
        "    return w, L_iters_train, L_iters_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjypcF51DzSJ"
      },
      "source": [
        "[Change Numpy to Tensor]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGWBSAoNzlCS"
      },
      "source": [
        "train_x1 = torch.DoubleTensor(x1_train)\n",
        "train_x2 = torch.DoubleTensor(x2_train)\n",
        "train_label = torch.DoubleTensor(data_train[:,2])\n",
        "\n",
        "test_x1 = torch.DoubleTensor(x1_test)\n",
        "test_x2 = torch.DoubleTensor(x2_test)\n",
        "test_label = torch.DoubleTensor(data_test[:,2])\n",
        "\n",
        "train_x1 = train_x1.unsqueeze(1)\n",
        "train_x2 = train_x2.unsqueeze(1)\n",
        "train_label = train_label.unsqueeze(1)\n",
        "\n",
        "test_x1 = test_x1.unsqueeze(1)\n",
        "test_x2 = test_x2.unsqueeze(1)\n",
        "test_label = test_label.unsqueeze(1)\n",
        "\n",
        "# construct the data matrix X\n",
        "X_train = function(train_x1, train_x2)\n",
        "X_test = function(test_x1, test_x2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eD2x0yiDJAxW"
      },
      "source": [
        "## 3. define a prediction function and run a gradient descent algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-woZiFi-hcYM"
      },
      "source": [
        "# run gradient descent algorithm\n",
        "tau = 1e-7; max_iter = 100000;\n",
        "w_0, train_L_0, test_L_0 = grad_desc(X_train, X_test, train_label, test_label, tau, max_iter, 0.00001)\n",
        "w_1, train_L_1, test_L_1 = grad_desc(X_train, X_test, train_label, test_label, tau, max_iter, 0.0001)\n",
        "w_2, train_L_2, test_L_2 = grad_desc(X_train, X_test, train_label, test_label, tau, max_iter, 0.001)\n",
        "w_3, train_L_3, test_L_3 = grad_desc(X_train, X_test, train_label, test_label, tau, max_iter, 0.01)\n",
        "w_4, train_L_4, test_L_4 = grad_desc(X_train, X_test, train_label, test_label, tau, max_iter, 0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlB82dU19ClP"
      },
      "source": [
        "# plot\n",
        "fig_3 = plt.figure()\n",
        "plt.plot(np.array(range(max_iter)), train_L_0, c = 'b', label='train loss')\n",
        "plt.plot(np.array(range(max_iter)), test_L_0, c = 'r', label='test loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss value')\n",
        "plt.title('Loss Curve (lamb = 0.00001)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "fig_3.savefig('Loss(lamb = 0.00001).png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68vOIjsoG87i"
      },
      "source": [
        "# plot\n",
        "fig_1 = plt.figure()\n",
        "plt.plot(np.array(range(max_iter)), train_L_1, c = 'b', label='train loss')\n",
        "plt.plot(np.array(range(max_iter)), test_L_1, c = 'r', label='test loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss value')\n",
        "plt.title('Loss Curve (lamb = 0.0001)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "fig_4.savefig('Loss(lamb = 0.0001).png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5USNU5Z7UMh"
      },
      "source": [
        "# plot\n",
        "fig_5 = plt.figure()\n",
        "plt.plot(np.array(range(max_iter)), train_L_2, c = 'b', label='train loss')\n",
        "plt.plot(np.array(range(max_iter)), test_L_2, c = 'r', label='test loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss value')\n",
        "plt.title('Loss Curve (lamb = 0.001)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "fig_5.savefig('Loss(lamb = 0.001).png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdEO5DiS1Cox"
      },
      "source": [
        "# plot\n",
        "fig_6 = plt.figure()\n",
        "plt.plot(np.array(range(max_iter)), train_L_3, c = 'b', label='train loss')\n",
        "plt.plot(np.array(range(max_iter)), test_L_3, c = 'r', label='test loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss value')\n",
        "plt.title('Loss Curve (lamb = 0.01)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "fig_6.savefig('Loss(lamb = 0.01).png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVN0YPUm6eti"
      },
      "source": [
        "# plot\n",
        "fig_7 = plt.figure()\n",
        "plt.plot(np.array(range(max_iter)), train_L_4, c = 'b', label='train loss')\n",
        "plt.plot(np.array(range(max_iter)), test_L_4, c = 'r', label='test loss')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss value')\n",
        "plt.title('Loss Curve (lamb = 0.1)')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "fig_7.savefig('Loss(lamb = 0.1).png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1osGymQpJOZg"
      },
      "source": [
        "## 4. Plot the decisoin boundary with probability map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pWPPKr1JN29"
      },
      "source": [
        "# compute values p(x) for multiple data points x\n",
        "x1_min, x1_max = x1_test.min(), x1_test.max() # min and max of grade 1\n",
        "x2_min, x2_max = x2_test.min(), x2_test.max() # min and max of grade 2\n",
        "xx1, xx2 = np.meshgrid(np.linspace(x1_min, x1_max), np.linspace(x2_min, x2_max)) # create meshgrid\n",
        "xx1 = torch.DoubleTensor(xx1)\n",
        "xx2 = torch.DoubleTensor(xx2)\n",
        "X2 = function(xx1.reshape(-1), xx2.reshape(-1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-anOdsZleAY"
      },
      "source": [
        "def pic_train_commons(ax, title, xx1, xx2, p):\n",
        "  ax.set_title(title)\n",
        "  ax.legend(loc = 'upper right')\n",
        "  ax.set_title('train')\n",
        "  ax.contourf(xx1,xx2,p,100,vmin=0,vmax=1,cmap='coolwarm', alpha=0.6)\n",
        "  ax.contour(xx1, xx2, p, [0.5], linewidths=2, colors='k') \n",
        "  ax.scatter(x1_train[idx_class0_train], x2_train[idx_class0_train], s=50, c='r', marker='.', label='label = 0') \n",
        "  ax.scatter(x1_train[idx_class1_train], x2_train[idx_class1_train], s=50, c='b', marker='.', label='label = 1')\n",
        "\n",
        "def pic_test_commons(ax, title, xx1, xx2, p):\n",
        "  ax.set_title(title)\n",
        "  ax.legend(loc = 'upper right')\n",
        "  ax.set_title('test')\n",
        "  ax.contourf(xx1,xx2,p,100,vmin=0,vmax=1,cmap='coolwarm', alpha=0.6)\n",
        "  ax.contour(xx1, xx2, p, [0.5], linewidths=2, colors='k') \n",
        "  ax.scatter(x1_test[idx_class0_train], x2_test[idx_class0_train], s=50, c='r', marker='.', label='label = 0') \n",
        "  ax.scatter(x1_test[idx_class1_train], x2_test[idx_class1_train], s=50, c='b', marker='.', label='label = 1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mK9wb3LtMRd"
      },
      "source": [
        "p = g_func(X2,w_0)\n",
        "p = p.reshape(50,50)\n",
        "p = p.numpy()\n",
        "\n",
        "# plot\n",
        "fig_8, ax = plt.figure(1,2)\n",
        "plt.title('lambda = 0.00001')\n",
        "pic_train_commons(ax[0], title, xx1, xx2, p)\n",
        "pic_train_commons(ax[1], title, xx1, xx2, p)\n",
        "plt.show()\n",
        "fig_8.savefig('Probability Map (Lambda = 0.00001).png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LStRwIGLM9QN"
      },
      "source": [
        "p = g_func(X2,w_1)\n",
        "p = p.reshape(50,50)\n",
        "p = p.numpy()\n",
        "\n",
        "# plot\n",
        "fig_9, ax = plt.figure(1,2)\n",
        "plt.title('lambda = 0.00001')\n",
        "pic_train_commons(ax[0], title, xx1, xx2, p)\n",
        "pic_train_commons(ax[1], title, xx1, xx2, p)\n",
        "plt.show()\n",
        "fig_9.savefig('Probability Map (Lambda = 0.0001).png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYTTVyqpauSF"
      },
      "source": [
        "p = g_func(X2,w_2)\n",
        "p = p.reshape(50,50)\n",
        "p = p.numpy()\n",
        "\n",
        "# plot\n",
        "fig_10, ax = plt.figure(1,2)\n",
        "plt.title('lambda = 0.001')\n",
        "pic_train_commons(ax[0], title, xx1, xx2, p)\n",
        "pic_train_commons(ax[1], title, xx1, xx2, p)\n",
        "plt.show()\n",
        "fig_10.savefig('Probability Map (Lambda = 0.001).png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W1SPmlra1Xd"
      },
      "source": [
        "p = g_func(X2,w_3)\n",
        "p = p.reshape(50,50)\n",
        "p = p.numpy()\n",
        "\n",
        "# plot\n",
        "fig_11, ax = plt.figure(1,2)\n",
        "plt.title('lambda = 0.01')\n",
        "pic_train_commons(ax[0], title, xx1, xx2, p)\n",
        "pic_train_commons(ax[1], title, xx1, xx2, p)\n",
        "plt.show()\n",
        "fig_11.savefig('Probability Map (Lambda = 0.01).png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQcGx6EKa6_z"
      },
      "source": [
        "p = g_func(X2,w_4)\n",
        "p = p.reshape(50,50)\n",
        "p = p.numpy()\n",
        "\n",
        "# plot\n",
        "fig_12, ax = plt.figure(1,2)\n",
        "plt.title('lambda = 0.1')\n",
        "pic_train_commons(ax[0], title, xx1, xx2, p)\n",
        "pic_train_commons(ax[1], title, xx1, xx2, p)\n",
        "plt.show()\n",
        "fig_12.savefig('Probability Map (Lambda = 0.1).png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaBs0T17Jd45"
      },
      "source": [
        "## 5. Compute the classification accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3knwItE3d_KW"
      },
      "source": [
        "n = data_train.shape[0]\n",
        "idx_class0 = (data_train[:,2]==0) # index of class0\n",
        "idx_class1 = (data_train[:,2]==1) # index of class1\n",
        "\n",
        "p_train_0 = g_func(X_train, w_0).numpy()\n",
        "p_train_1 = g_func(X_train, w_1).numpy()\n",
        "p_train_2 = g_func(X_train, w_2).numpy()\n",
        "p_train_3 = g_func(X_train, w_3).numpy()\n",
        "p_train_4 = g_func(X_train, w_4).numpy()\n",
        "\n",
        "idx_train_0 = (p_train_0 < 0.5)\n",
        "idx_train_1 = (p_train_1 < 0.5)\n",
        "idx_train_2 = (p_train_2 < 0.5)\n",
        "idx_train_3 = (p_train_3 < 0.5)\n",
        "idx_train_4 = (p_train_4 < 0.5)\n",
        "\n",
        "idx_right_0 = (idx_class0 == idx_train_0.reshape(-1))\n",
        "idx_right_1 = (idx_class0 == idx_train_1.reshape(-1))\n",
        "idx_right_2 = (idx_class0 == idx_train_2.reshape(-1))\n",
        "idx_right_3 = (idx_class0 == idx_train_3.reshape(-1))\n",
        "idx_right_4 = (idx_class0 == idx_train_4.reshape(-1))\n",
        "\n",
        "acc_train_0 = sum(idx_right_0)/n * 100\n",
        "acc_train_1 = sum(idx_right_1)/n * 100\n",
        "acc_train_2 = sum(idx_right_2)/n * 100\n",
        "acc_train_3 = sum(idx_right_3)/n * 100\n",
        "acc_train_4 = sum(idx_right_4)/n * 100\n",
        "acc_train = [acc_train_0, acc_train_1, acc_train_2, acc_train_3, acc_train_4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiRqDA3jjFfg"
      },
      "source": [
        "n = data_test.shape[0]\n",
        "idx_class0 = (data_test[:,2]==0) # index of class0\n",
        "idx_class1 = (data_test[:,2]==1) # index of class1\n",
        "\n",
        "p_0 = g_func(X_test, w_0).numpy()\n",
        "p_1 = g_func(X_test, w_1).numpy()\n",
        "p_2 = g_func(X_test, w_2).numpy()\n",
        "p_3 = g_func(X_test, w_3).numpy()\n",
        "p_4 = g_func(X_test, w_4).numpy()\n",
        "\n",
        "idx_0 = (p_0 < 0.5)\n",
        "idx_1 = (p_1 < 0.5)\n",
        "idx_2 = (p_2 < 0.5)\n",
        "idx_3 = (p_3 < 0.5)\n",
        "idx_4 = (p_4 < 0.5)\n",
        "\n",
        "idx_right_0 = (idx_class0 == idx_0.reshape(-1))\n",
        "idx_right_1 = (idx_class0 == idx_1.reshape(-1))\n",
        "idx_right_2 = (idx_class0 == idx_2.reshape(-1))\n",
        "idx_right_3 = (idx_class0 == idx_3.reshape(-1))\n",
        "idx_right_4 = (idx_class0 == idx_4.reshape(-1))\n",
        "\n",
        "acc_test_0 = sum(idx_right_0)/n * 100\n",
        "acc_test_1 = sum(idx_right_1)/n * 100\n",
        "acc_test_2 = sum(idx_right_2)/n * 100\n",
        "acc_test_3 = sum(idx_right_3)/n * 100\n",
        "acc_test_4 = sum(idx_right_4)/n * 100\n",
        "acc_test = [acc_test_0, acc_test_1, acc_test_2, acc_test_3, acc_test_4]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Ckaa252dC1C"
      },
      "source": [
        "Data Frame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QntslMzldCbJ"
      },
      "source": [
        "from pandas import Series, DataFrame\n",
        "import pandas ad pd\n",
        "data = {'train_accuracy(%)' : acc_train,\n",
        "        'test_accuracy(%)' : acc_test}\n",
        "\n",
        "train_frame = DataFrame (data, colums = ['train_accuracy(%)']\n",
        "        index = [0.00001, 0.0001, 0.001, 0.01, 0.1])\n",
        "\n",
        "test_frame = DataFrame (data, colums = ['test_accuracy(%)']\n",
        "        index = [0.00001, 0.0001, 0.001, 0.01, 0.1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCk49rhidEzN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsezpeV8Dtgo"
      },
      "source": [
        "# OUTPUT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4mboRZ0D1Wm"
      },
      "source": [
        "## 1. Plot the training data [0.5pt] "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDpchonsD0Q9"
      },
      "source": [
        "fig_1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBz0oCbND6nu"
      },
      "source": [
        "## 2. Plot the testing data [0.5pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cp7CvddD9fg"
      },
      "source": [
        "fig_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDqImovMD-QK"
      },
      "source": [
        "## 3. Plot the learning curve with λ=0.00001 [1pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiwxpNKREBpQ"
      },
      "source": [
        "fig_3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGVMnxYqEIFL"
      },
      "source": [
        "## 4. Plot the learning curve with λ=0.0001 [1pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NbOZKLdEPdu"
      },
      "source": [
        "fig_4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdBB3DNvERhI"
      },
      "source": [
        "## 5. Plot the learning curve with λ=0.001 [1pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb5tczFJEVB0"
      },
      "source": [
        "fig_5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvgMCmN3EVll"
      },
      "source": [
        "## 6. Plot the learning curve with λ=0.01 [1pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTEMsAsOEXy1"
      },
      "source": [
        "fig_6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4_f1GhtEY4W"
      },
      "source": [
        "## 7. Plot the learning curve with λ=0.1 [1pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uoZBaz-EbOR"
      },
      "source": [
        "fig_7"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FKVM93tEc7o"
      },
      "source": [
        "## 8. Plot the probability map of the obtained classifier with λ=0.00001 [1pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oRnuPe5Eg6k"
      },
      "source": [
        "fig_8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MB6BOYzElFs"
      },
      "source": [
        "## 9. Plot the probability map of the obtained classifier with λ=0.0001 [1pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBoAUENxEl3W"
      },
      "source": [
        "fig_9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dvz6O6d4EpHo"
      },
      "source": [
        "## 10. Plot the probability map of the obtained classifier with λ=0.001 [1pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeEg1NTJEq9H"
      },
      "source": [
        "fig_10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijBtX4y7Erpw"
      },
      "source": [
        "## 11. Plot the probability map of the obtained classifier with λ=0.01 [1pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPNLuqM4Eu13"
      },
      "source": [
        "fig_11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IHkIVp5Evlv"
      },
      "source": [
        "## 12. Plot the probability map of the obtained classifier with λ=0.1 [1pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpCwpRgKEypH"
      },
      "source": [
        "fig_12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO66b4TNE0tJ"
      },
      "source": [
        "##13. Print the final training accuracy with the given regularization parameters [2.5pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pwGBuwTuE9OG"
      },
      "source": [
        "train_frame = DataFrame (data, colums = ['train_accuracy(%)']\n",
        "          index = [0.00001, 0.0001, 0.001, 0.01, 0.1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruuNcRlYE5Ec"
      },
      "source": [
        "##14. Print the final testing accuracy with the given regularization parameters [2.5pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHH8TdeLE4Ys"
      },
      "source": [
        "test_frame = DataFrame (data, colums = ['test_accuracy(%)']\n",
        "        index = [0.00001, 0.0001, 0.001, 0.01, 0.1])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}