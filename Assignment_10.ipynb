{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_10.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOXsa4VXnE/Nuv0mQ46Up/k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yesoly/MachineLearningProject/blob/master/Assignment_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx7bjb1zOwMm"
      },
      "source": [
        "# Optimal Selection of the hyper-parameters associated with the classification on MNIST\n",
        "Choose an optimal set of hyper-parameters and design a neural network for the classification of MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoLzwBZTO3_w"
      },
      "source": [
        "## 1. Data\n",
        "* you can use any data normalisation method\n",
        "* one example of the data normalisation is whitenning as given by:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aAcS6JJO1MU"
      },
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,),(0.3081,)),  # mean value = 0.1307, standard deviation value = 0.3081\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVIk29VmPBl6"
      },
      "source": [
        "* load the MNIST dataset\n",
        "* use the original training dataset for testing your model\n",
        "* use the original testing dataset for training your model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FESTOm1nOv7e"
      },
      "source": [
        "data_path = './MNIST'\n",
        "\n",
        "data_test   = datasets.MNIST(root = data_path, train= True, download=True, transform= transform)\n",
        "data_train  = datasets.MNIST(root = data_path, train= False, download=True, transform= transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEI8L3lIPIk1"
      },
      "source": [
        "* Note that the number of your training data must be 10,000\n",
        "* Note that the number of your testing data must be 60,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwHjktlEOv1Q"
      },
      "source": [
        "print(\"the number of your training data (must be 10,000) = \", data_train.__len__())\n",
        "print(\"hte number of your testing data (must be 60,000) = \", data_test.__len__())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYeRoqwGPMvq"
      },
      "source": [
        "## 2. Model\n",
        "\n",
        "* design a neural network architecture with three layers (input layer, one hidden layer and output layer)\n",
        "* the input dimension of the input layer should be 784 (28 * 28)\n",
        "* the output dimension of the output layer should be 10 (class of digits)\n",
        "* all the layers should be fully connected layers\n",
        "* use any type of activation functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiBNYfzZOqM9"
      },
      "source": [
        "class classification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(classification, self).__init__()\n",
        "        \n",
        "        # construct layers for a neural network\n",
        "        self.classifier1 = nn.Sequential(\n",
        "            nn.Linear(in_features=28*28, out_features=dim_layer1_out),\n",
        "            nn.activation_layer1,\n",
        "        ) \n",
        "        self.classifier2 = nn.Sequential(\n",
        "            nn.Linear(in_features=dim_layer2_in, out_features=dim_layer2_out),\n",
        "            nn.activation_layer2,\n",
        "        ) \n",
        "        self.classifier3 = nn.Sequential(\n",
        "            nn.Linear(in_features=dim_layer3_in, out_features=10),\n",
        "            nn.activation_layer3,\n",
        "        ) \n",
        "    \n",
        "    def forward(self, inputs):                 # [batchSize, 1, 28, 28]\n",
        "        x = inputs.view(inputs.size(0), -1)    # [batchSize, 28*28]\n",
        "        x = self.classifier1(x)                # [batchSize, 20*20]\n",
        "        x = self.classifier2(x)                # [batchSize, 10*10]\n",
        "        out = self.classifier3(x)              # [batchSize, 10]\n",
        "        \n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUjvEAvoPXEd"
      },
      "source": [
        "## 3. Loss function\n",
        "* use any type of loss function\n",
        "* design the output of the output layer considering your loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28p5aYttPY4V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4FsFtk9Pck9"
      },
      "source": [
        "## 4. Optimization\n",
        "* use any stochastic gradient descent algorithm for the optimization\n",
        "* use any size of the mini-batch\n",
        "* use any optimization algorithm (for example, Momentum, AdaGrad, RMSProp, Adam)\n",
        "* use any regularization algorithm (for example, Dropout, Weight Decay)\n",
        "* use any annealing scheme for the learning rate (for example, constant, decay, staircase)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWxEtzMPPoeL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i9TQxoTPouU"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOuVvpn6PtSp"
      },
      "source": [
        "1. Plot the training and testing losses over epochs [2pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU_xNM1JPsmR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7w-v2BvGPu1B"
      },
      "source": [
        "2. Plot the training and testing accuracies over epochs [2pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDmdXkrVPqwZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ65cvaWPxYR"
      },
      "source": [
        "3. Print the final training and testing losses at convergence [2pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-vcO-FgPzoJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEEeO91oPz6x"
      },
      "source": [
        "4. Print the final training and testing accuracies at convergence [20pt]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMoFM6bUP0nB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}